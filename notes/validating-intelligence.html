<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">
    <title>The Paradox of Measuring Intelligence</title>
    <link rel="stylesheet" href="../css/basic.css">
</head>

<body>
    <h1>The Paradox of Measuring Intelligence</h1>

    <p class="info">
        January 2021
    </p>

    Intelligence is not the intrinsic property of a living being, it is a
    feature granted (or not) by an oberserver, says Rodney Brooks (the author of
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889005800259">"Elephants don't play chess"</a>).
    That's why we've had Turing's test so far. But Brooks even questions the
    relevance of Turing's test as it implies that an intelligent agent must be
    able to speak the same language as the observer. Elephant don't, and yet,
    humans tend to consider them as intelligent beings.

    The problem of intelligence might be the impossibility of 'measuring' it
    objectively, as if it were a physical quantity.

    Dilemma: measuring intelligence implies the reproducibility of its measure.
    A measure implies no adaptation by the subject. Yet, intelligence is
    commonly associated with learning. If an animal always behaves the same way
    under identical circumstances, we would tend to consider it a tropistic
    system, rather than a 'living thing'.

    Solutions to circumvent this paradox? The problem of the measure influencing
    the measured system is already well-known in quantum physics. The
    mathematical models used by physicists are more complex but not unsound
    (probabilities, non-commutative algebras, ...). What would suit best AI?

    ---

    Epistemic change with ANNs: we go back to empirical science (as opposed to
    maths and logic?). Hence the importance of reproducibility.

    Stuart Russell (PFIA keynote): cooperative game theory, where an agent
    tries to maximize our (uncertain) objective function.
</body>
<html>